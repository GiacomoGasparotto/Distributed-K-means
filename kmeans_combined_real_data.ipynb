{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functools import singledispatch\n",
    "\n",
    "# dataset\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pyspark module\n",
    "from pyspark.rdd import RDD\n",
    "\n",
    "# src module\n",
    "from src.utils import kddSetup, sparkSetup\n",
    "from src.kmeans import compute_centroidDistances, get_clusterId, get_minDistance, \\\n",
    "    kMeansParallel_init, kMeansPlusPlus_init, kMeansRandom_init, \\\n",
    "    miniBatchKMeans, naiveKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the zipped environment if it doesn't already exist\n",
    "! if [ ! -f \"environment.tar.gz\" ]; then venv-pack -o \"environment.tar.gz\" ; fi\n",
    "# creating the zipped module src\n",
    "! if [ -f \"src.tar.gz\" ]; then rm src.tar.gz ; fi\n",
    "! tar -czf src.tar.gz src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf3e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the cluster\n",
    "! $SPARK_HOME/sbin/start-all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# telling spark where to find the python binary\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"./environment/bin/python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a sparkSession\n",
    "spark = sparkSetup(\"kMeans\")\n",
    "sc = spark.sparkContext\n",
    "# exporting the src module\n",
    "sc.addPyFile(\"src.tar.gz\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf1762",
   "metadata": {},
   "source": [
    "### Naming conventions\n",
    "\n",
    "The single datum is named as `datumName`, while the RDD that is a collection of one or more data is called `datumName_rdd`.\n",
    "\n",
    "Example: `compute_clusterDistances` returns `clusterDistances` (i.e. a numpy array of distances between a point `x` and the `centroids`). \n",
    "The RDD that collects all the `clusterDistances` will be called `clusterDistances_rdd`, and here is a sample implementation of that:\n",
    "```python\n",
    "def compute_centroidDistances(x, centroids):\n",
    "    return np.sum((centroids - x)**2, axis = 1)\n",
    "\n",
    "# `data_rdd` is an RDD\n",
    "# `centroids` is a numpy array\n",
    "clusterDistances_rdd = data_rdd \\\n",
    "    .map(lambda x: compute_clusterDistances(x, centroids))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a86e34",
   "metadata": {},
   "source": [
    "### Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_data, kdd_labels, entries_dict = kddSetup(standardize=True)\n",
    "\n",
    "# get the number of clusters from kdd_labels\n",
    "k = np.unique(kdd_labels).shape[0]\n",
    "\n",
    "#parallelize\n",
    "data_rdd = sc.parallelize([row for row in kdd_data])\n",
    "data_rdd = data_rdd.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119cdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "l = k * 10\n",
    "centroids = kMeansParallel_init(data_rdd, k, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30762a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_centroids = miniBatchKMeans(data_rdd, centroids, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f852301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopping the cluster\n",
    "! $SPARK_HOME/sbin/stop-all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3859b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
